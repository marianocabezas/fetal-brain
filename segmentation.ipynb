{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878215f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "training_path = 'training_set/'\n",
    "testing_path = 'testing_set/'\n",
    "csv_name = 'parameters.csv'\n",
    "im_suffix = 'HC.png'\n",
    "n_folds = 5\n",
    "val_split = 0.1\n",
    "train_size = 8\n",
    "test_size = 8\n",
    "epochs = 50\n",
    "patience = 50\n",
    "subjects = sorted([\n",
    "    f for f in os.listdir(training_path)\n",
    "    if f.endswith(im_suffix)\n",
    "])\n",
    "\n",
    "im_size = (540, 800)\n",
    "half_x = im_size[1] / 2\n",
    "half_y = im_size[0] / 2\n",
    "\n",
    "n_points = 1000\n",
    "angles = (np.arange(n_points) / n_points) * 2 * np.pi\n",
    "\n",
    "fig = plt.figure(figsize=(32, 42))\n",
    "\n",
    "for i in range(n_folds):\n",
    "    fold_ini = len(subjects) * i // n_folds\n",
    "    fold_end = len(subjects) * (i + 1) // n_folds\n",
    "    \n",
    "    training_set = subjects[fold_end:] + subjects[:fold_ini]\n",
    "\n",
    "    # We account for a validation set or the lack of it. The reason for\n",
    "    # this is that we want to measure forgetting and that is easier to\n",
    "    # measure if we only focus on the training set and leave the testing\n",
    "    # set as an independent generalisation test.\n",
    "    if val_split > 0:\n",
    "        n_training = int(len(training_set))\n",
    "        training_set = training_set[int(n_training * val_split):]\n",
    "        validation_set = training_set[:int(n_training * val_split)]\n",
    "    else:\n",
    "        validation_set = training_set\n",
    "        \n",
    "    # Testing set for the current fold\n",
    "    testing_set = subjects[fold_ini:fold_end]\n",
    "    \n",
    "    # net = ConvNeXtTiny()\n",
    "    net = SimpleUNet()\n",
    "    \n",
    "    print('< Training dataset >')\n",
    "    train_dataset = SkullUSDataset(training_path, csv_name, sub_list=training_set)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, train_size, True, num_workers=1\n",
    "    )\n",
    "    \n",
    "    print('< Validation dataset >')\n",
    "    val_dataset = SkullUSDataset(training_path, csv_name, sub_list=validation_set)\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, test_size, num_workers=1\n",
    "    )\n",
    "    \n",
    "    print('< Testing dataset >')\n",
    "    test_dataset = SkullUSDataset(training_path, csv_name, sub_list=testing_set)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, test_size, num_workers=1\n",
    "    )\n",
    "    \n",
    "    print(\n",
    "        'Training / validation / test samples samples = '\n",
    "        '{:03d} / {:03d} / {:03d} ({:d} parameters)'.format(\n",
    "            len(train_dataset), len(val_dataset), len(test_dataset),\n",
    "            sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    net.fit(\n",
    "        train_loader, val_loader, epochs=epochs, patience=patience\n",
    "    )\n",
    "    \n",
    "    net.eval()\n",
    "    batch_j = 0\n",
    "    for im, (true, _, params) in test_loader:\n",
    "        with torch.no_grad():\n",
    "            pred_batch = torch.sigmoid(net(im.to(net.device))).detach().cpu()\n",
    "        for norm_p, gt, seg, im_j in zip(params.numpy(), true, pred_batch, im):\n",
    "#             brain_mask = seg.numpy() > 0\n",
    "#             inner_brain = binary_erosion(brain_mask)\n",
    "#             outer_brain = torch.from_numpy(\n",
    "#                 np.logical_and(\n",
    "#                     brain_mask, np.logical_not(inner_brain)\n",
    "#                 )\n",
    "#             )\n",
    "#             pred_a, pred_b, pred_x0, pred_y0, pred_theta = fit_ellipse(outer_brain)\n",
    "            pred_a, pred_b, pred_x0, pred_y0, pred_theta = fit_ellipse(seg.squeeze().numpy() > 0.5)\n",
    "#             prednorm_a, prednorm_b, prednorm_x0, prednorm_y0, pred_theta = pred\n",
    "            norm_a, norm_b, norm_x0, norm_y0, norm_theta = norm_p\n",
    "            true_a = norm_a * half_x + half_x\n",
    "            true_b = norm_b * half_y + half_y\n",
    "            true_x0 = norm_x0 * half_x + half_x\n",
    "            true_y0 = norm_y0 * half_y + half_y\n",
    "            true_theta = norm_theta * np.pi\n",
    "#             pred_a = prednorm_a * half_x + half_x\n",
    "#             pred_b = prednorm_b * half_y + half_y\n",
    "#             pred_x0 = prednorm_x0 * half_x + half_x\n",
    "#             pred_y0 = prednorm_y0 * half_y + half_y\n",
    "            print(true_x0, pred_x0, true_y0, pred_y0)\n",
    "            fig.clear()\n",
    "#             plt.subplot(2, 1, 1)\n",
    "            norm_im = (im_j[:1, ...] - torch.min(im_j)) / (torch.max(im_j) - torch.min(im_j))\n",
    "            segmentation = np.moveaxis(\n",
    "                torch.cat([seg > 0.5, gt, norm_im]).detach().cpu().numpy(), 0, -1\n",
    "            )\n",
    "            plt.imshow(segmentation)\n",
    "#             plt.imshow(im_j[0, ...], cmap='gray')\n",
    "            ideal_x = true_a * np.cos(angles)\n",
    "            ideal_y = true_b * np.sin(angles)\n",
    "            new_x = ideal_x * np.cos(true_theta) - ideal_y * np.sin(true_theta) + true_x0\n",
    "            new_y = ideal_y * np.cos(true_theta) + ideal_x * np.sin(true_theta) + true_y0\n",
    "            plt.scatter(new_x, new_y, c='g')\n",
    "            plt.scatter(true_x0, true_y0, c='g')\n",
    "            \n",
    "            ideal_x = pred_a * np.cos(angles)\n",
    "            ideal_y = pred_b * np.sin(angles)\n",
    "\n",
    "            new_x = ideal_x * np.cos(pred_theta) - ideal_y * np.sin(pred_theta) + pred_x0\n",
    "            new_y = ideal_y * np.cos(pred_theta) + ideal_x * np.sin(pred_theta) + pred_y0\n",
    "\n",
    "#             plt.scatter(new_x, new_y, s=1, c='r')\n",
    "            plt.scatter(pred_x0, pred_y0, s=1, c='r')\n",
    "#             plt.subplot(2, 1, 2)\n",
    "#             norm_im = (im_j[:1, ...] - torch.min(im_j)) / (torch.max(im_j) - torch.min(im_j))\n",
    "#             segmentation = np.moveaxis(\n",
    "#                 torch.cat([outer_brain, gt, norm_im]).detach().cpu().numpy(), 0, -1\n",
    "#             )\n",
    "#             plt.imshow(segmentation)\n",
    "            \n",
    "            plt.scatter(new_x, new_y, c='r')\n",
    "            plt.scatter(pred_x0, pred_y0, c='r')\n",
    "            plt.savefig(\n",
    "                os.path.join(\n",
    "                    testing_path,\n",
    "                    'unet_f{:02d}_b{:03d}.png'.format(i, batch_j)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            batch_j += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
